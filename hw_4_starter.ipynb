{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c8e3e7",
   "metadata": {},
   "source": [
    "# Recommender Systems using Surprise\n",
    "---\n",
    "\n",
    "Welcome to this skeleton notebook on using the Surprise library for solving recommender system problems. The purpose of this notebook is to provide you with an overview of the key concepts and steps involved in building a recommender system using Surprise. The notebook comes with utility code that you will need to fill in with key code snippets that are missing, marked as **#TODO**. There are a total of **8** sections marked as **#TODO**.\n",
    "\n",
    "The ultimate objective of this notebook is to make accurate predictions for the specified users in the last 2 cells of the notebook.\n",
    "\n",
    "To successfully complete this notebook, you will need to have basic knowledge of Python programming and familiarity with the Surprise library. We recommend following the notebook in sequential order and reading the instructions carefully before filling in the missing code snippets. Remember to save your notebook frequently as you work through it. If you encounter any issues, consult the Surprise documentation or seek help from the online community. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0960217f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in c:\\users\\ashut\\dev\\languages\\python\\python37\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\ashut\\dev\\languages\\python\\python37\\lib\\site-packages (from scikit-surprise) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.11.2 in c:\\users\\ashut\\dev\\languages\\python\\python37\\lib\\site-packages (from scikit-surprise) (1.21.6)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\ashut\\dev\\languages\\python\\python37\\lib\\site-packages (from scikit-surprise) (1.16.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\ashut\\dev\\languages\\python\\python37\\lib\\site-packages (from scikit-surprise) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "# Credits-Prof Eirinaki, Rashmi Sharma and Aditya Patel\n",
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37145507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "# utility\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# surprise utility\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection.split import train_test_split\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "\n",
    "# models\n",
    "from surprise import KNNBasic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91185089",
   "metadata": {},
   "source": [
    "## Understanding the recommendations' generation problem:\n",
    "---\n",
    "\n",
    "### Basic recommender system design revolves around three fields:\n",
    "- user_id \n",
    "- item _id\n",
    "- rating\n",
    "\n",
    "As seen in class, major techniques to predict ratings of the user for an item are:\n",
    "- Collaborative Filtering\n",
    "- Matrix Factorization\n",
    "\n",
    "We will work through the **Collaborative Filtering** technique using Python's **Surprise** library which provides a lot of built in function tailored to build recommender system. [Link to Official Documentation](https://surprise.readthedocs.io/en/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb95f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating\n",
       "0     1      2     4.0\n",
       "1     1      3     5.0\n",
       "2     1      6     4.0\n",
       "3     1      8     3.0\n",
       "4     1     11     3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the utility matrix into a dataframe\n",
    "data = pd.read_csv('data/dataset.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4329f344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x291aed575c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the scale of ratings\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "#load dataset into Surprise data-structure: Dataset\n",
    "data = Dataset.load_from_df(data, reader)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a67cf8",
   "metadata": {},
   "source": [
    "## Training the Model:\n",
    "---\n",
    "\n",
    "There are several ways to train a recommender system using the Surprise library.\n",
    "\n",
    "The first way is to set similarity measures and employ one of the collaborative filtering algorithms (i.e. the \"original\" algorithms and their variations). There is also an option of using baseline estimates (i.e.minimizing error using some optimization).\n",
    "\n",
    "We follow the first approach here.\n",
    "\n",
    "### Neighborhood-based Collaborative Filtering:\n",
    "\n",
    "Before training the model, we need to create a training set. This needs to be distinct from any set used for cross-validation or testing/evaluation.\n",
    "\n",
    "There are several ways to perform hyperparameter tuning and/or evaluation.\n",
    "\n",
    "Surprise library provides several cross-validation iterators that allow to do the split from user-item matrix as below. (Ref: https://surprise.readthedocs.io/en/stable/getting_started.html#use-cross-validation-iterators)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968c857c",
   "metadata": {},
   "source": [
    "### Option 1: Using Holdout Set\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76efe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "# initial setup for training\n",
    "# create training set\n",
    "# test_size=0.2\n",
    "trainingSet, testSet = \n",
    "\n",
    "# let's configure some parameters for neighborhood-based Collaborative Filtering Algorithm\n",
    "sim_options = {\n",
    "    'name': 'pearson', #similarity measure default is MSD\n",
    "    'user_based': True #user-based CF\n",
    "}\n",
    "\n",
    "# other options:\n",
    "# for item-based CF -> False\n",
    "# for name -> pearson, cosine, msd, pearson_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fc608d",
   "metadata": {},
   "source": [
    "### 1a: Training KNN-based CF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aac452",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "## training\n",
    "# KNN -- implements neighborhood-based CF algorithms\n",
    "\n",
    "# define model\n",
    "# k=neighbours=5, other parameters set as above\n",
    "knn = \n",
    "\n",
    "# fit model to the training set\n",
    "knn.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4fccff",
   "metadata": {},
   "source": [
    "### 1b: Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3994bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "# look into test() to fetch predictions for testSet\n",
    "# predict for test set values\n",
    "predictions_knn = \n",
    "\n",
    "# evaluating rating predictions using RMSE\n",
    "accuracy.rmse(predictions_knn, verbose=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a155983",
   "metadata": {},
   "source": [
    "### 1c: Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d5df10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also predict for a particular user-item combination\n",
    "pred = knn.predict(4, 1, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fcf484",
   "metadata": {},
   "source": [
    "### Option 2: Cross Validation\n",
    "---\n",
    "\n",
    "Run a cross validation procedure for a given algorithm, reporting accuracy measures and computation times.\n",
    "\n",
    "You have several options in surprise library: https://surprise.readthedocs.io/en/stable/model_selection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62450bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "# use cross validation approach for training the knn model\n",
    "# instead of manual splitting the dataset\n",
    "# divides dataset into folds\n",
    "# uses each fold for training and testing by running many passes\n",
    "# final model performance is the average over the model performance in all passes\n",
    "\n",
    "# look into cross_validate() function\n",
    "# use both rmse and mae for measures\n",
    "# set number of folds as 5\n",
    "\n",
    "cross_validate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d2059",
   "metadata": {},
   "source": [
    "### Option 3: GridSearchCV\n",
    "---\n",
    "\n",
    "The GridSearchCV class computes accuracy metrics for an algorithm on various combinations of parameters, over a cross-validation procedure. \n",
    "\n",
    "This is useful for finding the best set of parameters for a prediction algorithm. It is analogous to GridSearchCV from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28576daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "# define the set of parameters to be searched on\n",
    "param_grid = {\n",
    "    'k': [3, 5, 10, 20],\n",
    "    'sim_options': {\n",
    "        'name': ['pearson', 'cosine'],\n",
    "        'min_support': [1, 5],   #the minimum number of common items needed between users to consider them for similarity. For the item-based approach, this corresponds to the minimum number of common users for two items.\n",
    "        'user_based': [False, True]\n",
    "    }\n",
    "}\n",
    "\n",
    "# find optimal params for KNN\n",
    "# create object of GridSearchCV for KNNBasic model\n",
    "# look into the required parameters to the GridSearchCV() constructor\n",
    "# pass model as KNNBasic\n",
    "# use both rmse and mae as measures\n",
    "# keep number of cross validation folds as 5\n",
    "\n",
    "gs = GridSearchCV()\n",
    "\n",
    "# fit the model on training data\n",
    "# entire data used for GridSearchCV\n",
    "# data used, not trainSet\n",
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28bde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "# print best RMSE score\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a69f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "# print combination of parameters that gave the best RMSE score\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cc8cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the best model\n",
    "knn = gs.best_estimator['rmse']\n",
    "\n",
    "# train the best model on the trainset\n",
    "knn.fit(data.build_full_trainset())\n",
    "\n",
    "# You may use this instead of some parts of the following section, to make predictions for the unseen data (i.e. all the missing ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64d8bb2",
   "metadata": {},
   "source": [
    "## Example: Making Predictions for Unknown Ratings\n",
    "---\n",
    "\n",
    "### UI Prep:\n",
    "\n",
    "For our demo, we will create a user dictionary and movie dictionary, where for the user dictionary the key is user_name and the value is the userId (which is used in our original dataset). For the movie dictionary the key is movieId and value is movie_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c793041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>SPRING-18-660</td>\n",
       "      <td>341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>FALL-19-352</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>FALL-18-288</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>SPRING-18-788</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>SPRING-20-767</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          username   id\n",
       "340  SPRING-18-660  341\n",
       "164    FALL-19-352  165\n",
       "237    FALL-18-288  238\n",
       "362  SPRING-18-788  363\n",
       "120  SPRING-20-767  121"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = pd.read_csv(\"data/user_name.csv\")\n",
    "user_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38b03b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {}\n",
    "for i in range(len(user_df)):\n",
    "    user_dict[user_df.iloc[i].username] = user_df.iloc[i].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbe7ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieName</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rating [Rogue One/Star Wars]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rating [Fight Club]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rating [The Lord of the Rings]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rating [Trolls]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rating [Despicable Me]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        movieName  id\n",
       "0    Rating [Rogue One/Star Wars]   1\n",
       "1             Rating [Fight Club]   2\n",
       "2  Rating [The Lord of the Rings]   3\n",
       "3                 Rating [Trolls]   4\n",
       "4          Rating [Despicable Me]   5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df = pd.read_csv(\"data/movie_name.csv\")\n",
    "movie_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2eef484",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dict = {}\n",
    "for i in range(len(movie_df)):\n",
    "    movie_dict[movie_df.iloc[i].id] = movie_df.iloc[i].movieName"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465deb8",
   "metadata": {},
   "source": [
    "### Find user-item pairs with no ratings:\n",
    "\n",
    "The **build_anti_testset()** function returns all the ratings that are not in the trainset, i.e. all the ratings **𝑟𝑢𝑖** where the user **𝑢** is known, the item **𝑖** is known, but the rating **𝑟𝑢𝑖** is not in the trainset. \n",
    "\n",
    "As 𝑟𝑢𝑖 is unknown, it is either replaced by the fill value or assumed to be equal to the mean of all ratings (global_mean)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "715144d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the best model from gridSearchCV: knn\n",
    "\n",
    "# Find missing values and predict\n",
    "trainset = data.build_full_trainset()\n",
    "anti_test_set = trainset.build_anti_testset()\n",
    "predictions = knn.test(anti_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44aab949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def getMovieRecommendations(topN=3):\n",
    "    top_recs = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions: \n",
    "        top_recs[uid].append((iid, est))\n",
    "     \n",
    "    for uid, user_ratings in top_recs.items():\n",
    "        user_ratings.sort(key = lambda x: x[1], reverse = True)\n",
    "        top_recs[uid] = user_ratings[:topN]\n",
    "     \n",
    "    return top_recs\n",
    "\n",
    "\n",
    "'''\n",
    "The getMovieRecommendationsForUser fuction takes \n",
    "username, and recommendations \n",
    "which we get from getMovieRecommendations function.\n",
    "'''\n",
    "def getMovieName(movie_id):\n",
    "    if movie_id not in movie_dict:\n",
    "        return \"\"\n",
    "    m = movie_dict[movie_id].split('[')\n",
    "    temp = m[1].split(']')\n",
    "    return temp[0]\n",
    "\n",
    "\n",
    "def getMovieRecommendationsForUser(userId, recommendations):\n",
    "    if userId not in user_dict:\n",
    "        print(\"User id is not present\")\n",
    "        return\n",
    "    u_id = user_dict[userId]\n",
    "    recommended_movies = recommendations[u_id]\n",
    "    movie_list = []\n",
    "    for movie in recommended_movies:\n",
    "        movie_list.append((getMovieName(movie[0]),movie[1]))\n",
    "    return movie_list    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n",
    "\n",
    "# generate recommendations for all user, movie pairs\n",
    "# look into getMovieRecommendations() function defined above\n",
    "# set top similar neighbors value as 3\n",
    "recommendations = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56081653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract movie recommendations for a user from the above predictions\n",
    "getMovieRecommendationsForUser('SPRING-23-477',recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c8bb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when a user has rated everything? Here's a user from our dataset that has done that.\n",
    "getMovieRecommendationsForUser('SPRING-23-230',recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce5bf4b",
   "metadata": {},
   "source": [
    "## Tips\n",
    "1.Surprise dataset function just takes three columns,user, item and rating.\n",
    "\n",
    "2.Building Antitest set gives you all the unknown user-item ratings, you may not require all of them.\n",
    "\n",
    "3.Explore more and have fun!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
